{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Basics w/Requests and Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file explains the basic mechanisms for beginning Python learners to `scrape` the web. \n",
    "\n",
    "Requests and BeautifulSoup are very popular libraries used by many Python developers.\n",
    "\n",
    "By the end of this notebook you might even have a collection of new literature to read more about Python with!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign variables to Variables \n",
    "\n",
    "These will be used later in the code. In the future, we may want to import these variables from a .yaml or .json file. Configurations should be imported or extracted from a parsable, human-friendly config file. When setting up complex systems, it's nice to have configuration files thoughtfully organized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*html_target* refers to First html tag you want to scrape data from. \n",
    "\n",
    "*tag* refers to the string information you want to grab from a tag in that html_target\n",
    "\n",
    "*f_ext* is the filename extension you want to search for (scraping pdf files)\n",
    "\n",
    "*dir_name* is the name of the path you want to store the files in\n",
    "\n",
    "*url* is the base url you want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html_target = \"a\"\n",
    "tag = \"href\"\n",
    "f_ext = \".pdf\"\n",
    "dir_name = \"Ghodsi_Ali\"\n",
    "url = 'https://www.cs.berkeley.edu/~alig/papers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Request and Collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a request object and call the `.get` method on it. `r` is our `HTTP 1.1` response. \n",
    "\n",
    "From here we have:\n",
    "\n",
    "*    status\n",
    "*    encoding\n",
    "*    text of the body --- should type check this\n",
    "*    content of the body --- type binary\n",
    "\n",
    "Once we have our `html` we are ready to scrape the site for useful `href` tags`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "status = r.status_code\n",
    "encoding = r.encoding\n",
    "html_doc = r.text\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "anchor = soup(html_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_dir(directory):\n",
    "    \"\"\"\n",
    "    return: None\n",
    "    Makes directory if does not already exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download_url(url, endpoint)\n",
    "\n",
    "This function makes a new request each time it's called. It writes the binary content to file.\n",
    "This could be two functions. One to get the new request object/content. And the other to actually write that content to file. This modular design can be implemented by the reader if the reader is so inclined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_url(url, endpoint):\n",
    "    \"\"\"\n",
    "    return: None\n",
    "    downloads file, requires url in global or class scope.\n",
    "    \"\"\"\n",
    "    url_addr = \"{url}/{endpoint}\".format(url=url, endpoint=endpoint)\n",
    "    file_path = \"{directory}/{endpoint}\".format(directory=dir_name, endpoint=endpoint)\n",
    "    \n",
    "    r = requests.get(url_addr)\n",
    "    content_file = r.content\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        print \"\"\"Downloading From: {url}\\nWriting to: {file_path}\"\"\".format(\n",
    "                                                url=url_addr, \n",
    "                                                file_path=file_path\n",
    "                                                                    )\n",
    "        f.write(content_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script in action. Isolated like this, it looks very meager. It will be reconfigured as a series of method calls in the next iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Encoding: ISO-8859-1\n",
      "Begin downloading\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/architecting-for-innovation.pdf\n",
      "Writing to: test/architecting-for-innovation.pdf\n",
      "Finished Download -- architecting-for-innovation.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/bolt-on-causal-consistency.pdf\n",
      "Writing to: test/bolt-on-causal-consistency.pdf\n",
      "Finished Download -- bolt-on-causal-consistency.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/cap-for-networks.pdf\n",
      "Writing to: test/cap-for-networks.pdf\n",
      "Finished Download -- cap-for-networks.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/choosy.pdf\n",
      "Writing to: test/choosy.pdf\n",
      "Finished Download -- choosy.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/content-oriented-naming.pdf\n",
      "Writing to: test/content-oriented-naming.pdf\n",
      "Finished Download -- content-oriented-naming.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/dangers-causal-consistency.pdf\n",
      "Writing to: test/dangers-causal-consistency.pdf\n",
      "Finished Download -- dangers-causal-consistency.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/datacenter-needs-os.pdf\n",
      "Writing to: test/datacenter-needs-os.pdf\n",
      "Finished Download -- datacenter-needs-os.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/ddrf.pdf\n",
      "Writing to: test/ddrf.pdf\n",
      "Finished Download -- ddrf.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/disk-locality-irrelevant.pdf\n",
      "Writing to: test/disk-locality-irrelevant.pdf\n",
      "Finished Download -- disk-locality-irrelevant.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/dolly.pdf\n",
      "Writing to: test/dolly.pdf\n",
      "Finished Download -- dolly.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/drf.pdf\n",
      "Writing to: test/drf.pdf\n",
      "Finished Download -- drf.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/drfq.pdf\n",
      "Writing to: test/drfq.pdf\n",
      "Finished Download -- drfq.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/eventual-consistency-limitations-extensions.pdf\n",
      "Writing to: test/eventual-consistency-limitations-extensions.pdf\n",
      "Finished Download -- eventual-consistency-limitations-extensions.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/h-drf.pdf\n",
      "Writing to: test/h-drf.pdf\n",
      "Finished Download -- h-drf.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/hat-not-cap.pdf\n",
      "Writing to: test/hat-not-cap.pdf\n",
      "Finished Download -- hat-not-cap.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/hat-virtues-limitations.pdf\n",
      "Writing to: test/hat-virtues-limitations.pdf\n",
      "Finished Download -- hat-virtues-limitations.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/http.pdf\n",
      "Writing to: test/http.pdf\n",
      "Finished Download -- http.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/incremental-icn.pdf\n",
      "Writing to: test/incremental-icn.pdf\n",
      "Finished Download -- incremental-icn.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/information-centric-networking-seeing-the-forest-for-the-trees.pdf\n",
      "Writing to: test/information-centric-networking-seeing-the-forest-for-the-trees.pdf\n",
      "Finished Download -- information-centric-networking-seeing-the-forest-for-the-trees.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/intelligent-design-evolution.pdf\n",
      "Writing to: test/intelligent-design-evolution.pdf\n",
      "Finished Download -- intelligent-design-evolution.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/mesos.pdf\n",
      "Writing to: test/mesos.pdf\n",
      "Finished Download -- mesos.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/pacman.pdf\n",
      "Writing to: test/pacman.pdf\n",
      "Finished Download -- pacman.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/ramp.pdf\n",
      "Writing to: test/ramp.pdf\n",
      "Finished Download -- ramp.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/scalingspark.pdf\n",
      "Writing to: test/scalingspark.pdf\n",
      "Finished Download -- scalingspark.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/sdn-architecture.pdf\n",
      "Writing to: test/sdn-architecture.pdf\n",
      "Finished Download -- sdn-architecture.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/sparksql.pdf\n",
      "Writing to: test/sparksql.pdf\n",
      "Finished Download -- sparksql.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/tachyon-workshop.pdf\n",
      "Writing to: test/tachyon-workshop.pdf\n",
      "Finished Download -- tachyon-workshop.pdf\n",
      "Downloading From: https://www.cs.berkeley.edu/~alig/papers/tachyon.pdf\n",
      "Writing to: test/tachyon.pdf\n",
      "Finished Download -- tachyon.pdf\n",
      "Finished Downloading\n"
     ]
    }
   ],
   "source": [
    "print \"\"\"Status: {status}\\nEncoding: {encoding}\"\"\".format(status=status, \n",
    "                                                    encoding=encoding)\n",
    "print \"Begin downloading\"\n",
    "\n",
    "make_dir(dir_name)\n",
    "for a in anchor:\n",
    "    endpoint = a[tag]\n",
    "    if endpoint[-4:] == f_ext:\n",
    "            download_url(url, endpoint)\n",
    "            print \"Finished Download -- {tag}\".format(tag=endpoint)\n",
    "    #print \"miss: {tag}\".format(tag=endpoint)\n",
    "    \n",
    "print \"Finished Downloading\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
